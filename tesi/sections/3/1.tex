\documentclass[../3.tex]{subfiles}
\begin{document}
    In Chapter \ref{ch:2} we defined the convolution of $f:\R^n \to \R$ with $g:\R^n \to \R$ as
    \[ (f * g)(x) = \int_{\R^n} dx' f(x')g(x-x'), \]
    in the literature of convolutional neural networks the function $f$ is called the \ii{input} of the
    convolutional layer, the functions $g$ is called \ii{filter} and the output $f*g$ is called \ii{feature map}.

    To give an interpretation of convolution we will discuss an example from \cite{deep}.

    Suppose we are tracking the location of a spaceship with a laser sensor. Our
    sensor gives a single output $x : \R \to \R^3$, where $x(t)$ is the position read by the sensor at the time t.
    Now suppose that our laser sensor is somewhat noisy. To obtain a less noisy
    measurement of the spaceshipâ€™s position, we need to average several measurements.
    Considering that more recent measurements are more relevant, we will want this average to
    be a weighted average that gives more weight to recent measurements. 
    We can do this with a weighting function $w:\R \to \R$. If
    we apply such a weighted average operation at every moment, we obtain a new
    function s providing a smoothed estimate of the position of the spaceship:
    \[ s(t) = \int_\R da \, x(a)w(t-a), \]
    where $w(t-a)$ is the time-shifted weighting function.
    Since the aquisition rate of any measurement apparatus is not infinite, we need to see this convolution as discrete, representing time as a 1D grid,
    \[ s_i = \sum_{j \in \Z} x_j w_{(i-j)}, \]
    where $w_{(i-j)}$ is still the time-shifted weighting function shifted by an integer.
    Let us see for a moment $(\Z,+)$ as a group, since by definition it is closed under the addition this convolution is well defined.
    The representation of this convolution is given by an infinite circulant matrix, therefore a restriction of $\Z$
    into a subset $I$ is necessary. But what happens to $(i-j)$ at the boundary of $I$?\\
    The problem is that a finite interval $I$ is not closed under the addition in this case, namely it is not a group.
    Standard addition is therefore not qualified to be the group operation, yet if $I = \{ 0,\dots,n-1 \}$, we could use
    addition modulo $n$, i.e. 
    \[ s_i = \sum_{j = 0}^{n-1} x_j w_{(i-j) \, \text{mod} \, n},\]
    which gives a finite circulant matrix as convolution.
    This matrix being circulant has an important constraint on the number of independent components, this reflects the compact support of the filter.
    This might look as a pragmatic solution but it also tells us some truth about the symmetries of the task.
    In some cases the classification of a signal, e.g. voice recognition, is independent of the time when the signal was recorded,
    we can say that the classification is invariant under translations of the signal over time. This is reflected in the fact that if I 
    shift the whole cyclic group the matrix representing the convolution will still be circulant.
    At this point, we could see our filter as a function defined on the cyclic group itself, rather than a filter whose symmetry group is the cyclic group.
    This subtle distinction allowed M. Welling and T. S. Cohen to define in \cite{gcnn} a group equivariant convolution on an arbitrary group.
    
\end{document}