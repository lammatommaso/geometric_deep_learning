\documentclass[12pt,a4paper,twoside]{report}
\usepackage[english]{babel}
\usepackage{newlfont}
\usepackage{color}
\textwidth=450pt\oddsidemargin=0pt
\usepackage[utf8]{inputenc}
\usepackage{fouriernc}
\usepackage[T1]{fontenc}
\usepackage{adjustbox}
\usepackage[margin=2cm]{geometry}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{tikz}
\usepackage[colorlinks=true,linkcolor=black,urlcolor=black, citecolor=black]{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{subfiles}
\usepackage{comment}
\usepackage{float}
\usepackage{enumerate}
\usepackage{appendix}
\usepackage[style=numeric, backend=biber, sorting=nty]{biblatex}
\usepackage{chngcntr}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
% \fancyhead[LE]{\nouppercase \leftmark}
\fancyhead[R]{\nouppercase \rightmark}
\fancyfoot[R]{\thepage}

\fancypagestyle{plain}
{
    \fancyfoot[R]{\thepage}
    \fancyhead{}
    \renewcommand{\headrulewidth}{0pt}
}

% \renewcommand{\chaptermark}[1]{%
% \markboth{#1}{}}

\definecolor{SAEblue}{rgb}{0, .62, .91}
\renewcommand\theequation{{\color{SAEblue}\arabic{equation}}}

\addbibresource{bibliography.bib}

\setlength{\parindent}{0pt}
\makeatletter
\renewcommand{\fnum@figure}{Fig. \thefigure}
\makeatother


\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{exa}[thm]{Example}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{obs}[thm]{Observation}

% \AtAppendix{
%     \renewtheorem{thm}{Theorem}[chapter]
%     \renewtheorem{lem}[thm]{Lemma}
%     \renewtheorem{prop}[thm]{Proposition}
%     \renewtheorem{cor}[thm]{Corollary}
%     \renewtheorem{defn}[thm]{Definition}
%     \renewtheorem{exa}[thm]{Example}
%     \renewtheorem{rem}[thm]{Remark}
% }

%\setcounter{secnumdepth}{0} % no section numbering displayed, no idea how

\newcommand{\bb}[1]{\textbf{#1}}
\newcommand{\ii}[1]{\textit{#1}}
\newcommand{\eps}{\varepsilon}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\pder}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\eval}[1]{\Big{|}_{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mf}[1]{\mathfrak{#1}}
\newcommand{\bmc}[1]{\textbf\mathcal{#1}}
\newcommand{\scal}[2]{\langle #1, #2 \rangle}
\newcommand{\bra}[1]{\langle #1 |}
\newcommand{\ket}[1]{| #1 \rangle}
\newcommand{\braket}[2]{\langle #1 | #2 \rangle}
\newcommand{\del}{\partial}
\newcommand{\then}{\Rightarrow}
\newcommand{\hull}[1]{\langle #1 \rangle}
\newcommand{\m}{\text{-}}
% \newcommand{\ch}[1]{\langle #1 \rangle}
\newcommand{\ch}[1]{\ket{#1}}
% \newcommand{\cc}[1]{\varphi_{\langle #1 \rangle}}
\newcommand{\cc}[1]{\bra{#1}}
% \newcommand{\scal}[2]{#1 \cdot #2 }
\newcommand{\im}{\mathrm{im}\,}
% \newcommand{\ker}{\mathrm{ker}}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\dg}{deg}

\begin{document}
    \begin{titlepage}
        \subfile{sections/front}
    \end{titlepage}
    \begin{abstract}
        La maggior parte delle architetture di deep learning permettono alla macchian di imparare una partizione in classi d'equivalenza
        dell'insieme delle funzioni lisce definite su domini euclidei.
        Sebbene questo approccio abbia successo in molte applicazioni, è limitato a una piccola classe di domini.
        Lo scopo del geometric deep learning è quello di estendere questo approccio a domini non euclidei come i grafi e i complessi simpliciali.
    \end{abstract}
    \begin{abstract}
    Most of the deep learning techniques used today allow the machine to learn a partition of the set of smooth functions defined on euclidean 
    domains into task-related equivalence classes. Although this approach has been successful in modern machine learning, it only deals with a really 
    small set of domains. The goal of geometric deep learning is to extend this method to data defined on non euclidean domains such as graphs and simplicial
    complexes.
    \end{abstract}
    \pagenumbering{roman}
    %   \subfile{sections/abstract_ita}
    %    \newpage
    %    \subfile{sections/abstract_eng}
    %    \newpage
    \tableofcontents
    \newpage
    \pagenumbering{arabic}
    \begin{chapter}{Preliminaries on topology}
        \label{ch:1}
        \subfile{sections/1}
    \end{chapter}
    \begin{chapter}{Graphs}
        \label{ch:2}
        \subfile{sections/2}
    \end{chapter}
    \begin{chapter}{Geometric Deep Learning}
        \label{ch:3}      
        \subfile{sections/3}
    \end{chapter}
    \newpage
%    \chapter*{Conclusion}
%         Most of the deep learning techniques used today are based on models which learn a partition of the set of smooth functions defined on euclidean 
%         domains into human friendly equivalence classes. Although this approach has been successful in modern machine learning, it only deals with a really 
%         small set of domains. The goal of geometric deep learning is to extend this method to data defined on manifolds and simplicial complexes.\\
%     \addcontentsline{toc}{chapter}{Conclusion}
    \begin{appendices}
    \counterwithin{thm}{chapter}
        \begin{chapter}{Category Theory}
            \label{app:A}
            \subfile{sections/appendixA/main}
        \end{chapter}
        \begin{chapter}{Dirac's Notation}
            \label{app:B}
            \subfile{sections/appendixB/main}
        \end{chapter}
        \begin{chapter}{Laplacian Operators}
            \label{app:C}
            \subfile{sections/appendixC/main}
        \end{chapter}
    \end{appendices}
    \newpage
    \printbibliography[heading = bibintoc]
    % \chapter*{Ringraziamenti}
    % \begin{flushright}
    %     \vspace{8cm}
    %     Vorrei ringraziare la mia famiglia per la possibilità,\\ i colleghi e gli amici per il supporto\\ e il relatore per la pazienza.
    % \end{flushright}
\end{document}
